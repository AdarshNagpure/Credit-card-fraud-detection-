# -*- coding: utf-8 -*-
"""updated Credit card fraud detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17DWvq34U8oBw7uEXPBMOsdFJGb3yq4o9
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import random

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall

print(f"Version of TensorFlow : {tf.__version__}")

data = pd.read_csv("creditcard_2023.csv")

data.head()

print(f"Shape of data : {data.shape}")

"""## Preprocessing

##### Checking for duplicated data points and removing them
"""

duplicated_values = data.value_counts()
duplicated_values = duplicated_values.to_frame()
duplicated_values.head(10)

data = data.drop_duplicates()
data = data.reset_index()
data = data.drop(['index'], axis=1)
data.head()

print(f"Shape of updated data : {data.shape}")

"""##### Checking NaN values"""

data.isnull().sum()

"""#### Checking the distribution of the Class and Undersampling

Here, output y is called class
* If Class = 1 -> Fraud Transaction
* If Class = 0 -> Legit Transaction
"""

data['Class'].value_counts()

"""The data exhibits a significant bias towards legitimate transactions. A basic model predicting legitimate transactions every time would yield an accuracy of over 99%, which is not ideal. Therefore, #undersampling the data is necessary."""

legit_data = data[data['Class'] == 0]
fraud_data = data[data['Class'] == 1]

print(f"Shape of Legit Data : {legit_data.shape}")
print(f"Shape of Fraud Data : {fraud_data.shape}")

"""Taking random samples from Legit Data same as size of Fraud Data"""

legit_data_updated = legit_data.sample(n = fraud_data.shape[0])

print(f"Shape of Legit Data : {legit_data_updated.shape}")
print(f"Shape of Fraud Data : {fraud_data.shape}")

# Concatenate the data
data_updated = pd.concat([legit_data_updated, fraud_data], axis = 0)
data_updated

# randomly shuffling
data_updated = data_updated.sample(frac=1)
data_updated

data_updated['Class'].value_counts()

from imblearn.over_sampling import SMOTE
smt = SMOTE(sampling_strategy='auto', random_state=42)
X_dummy, y_dummy = smt.fit_resample(data_updated.iloc[:,:-1], data_updated.iloc[:,-1])

data_updated = pd.concat([X_dummy, y_dummy], axis=1)

"""## Splitting the dataset and Feature Selection"""

X = data_updated.iloc[:300000,:-1]
Y = data_updated.iloc[:300000,-1]

# from sklearn.ensemble import RandomForestClassifier
# import matplotlib.pyplot as plt

# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# # Fit the classifier to the training data
# rf_classifier.fit(X_train, Y_train)

# # Get feature importances from the trained model
# feature_importances = rf_classifier.feature_importances_

# # Create a DataFrame to display feature importances
# feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

# # Sort features by importance in descending order
# feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# # Plot the feature importances
# plt.figure(figsize=(10, 6))
# plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
# plt.xlabel('Feature Importance')
# plt.ylabel('Feature')
# plt.title('Random Forest Feature Importance')
# plt.show()

X = X.loc[:, ['V14','V10','V4','V12','V17','V16','V11','V3','V9','V2']]
X.head()

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.35, shuffle=True)

print(f"Shape of X_train : {X_train.shape}")
print(f"Shape of X_test : {X_test.shape}")
print(f"Shape of Y_train : {Y_train.shape}")
print(f"Shape of Y_test : {Y_test.shape}")

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print(f"Shape of X_train : {X_train.shape}")

# from sklearn.feature_selection import SelectKBest, mutual_info_classif
# from sklearn.datasets import make_classification
# # Get feature names
# feature_names = [f"Feature_{i}" for i in range(X_train.shape[1])]
# # Calculate mutual information scores
# mi_scores = mutual_info_classif(X_train, Y_train)

# # Select top k features with the highest mutual information scores
# top_k_features_mask = SelectKBest(mutual_info_classif, k=9).fit(X_train, Y_train).get_support()

# # Get the names of selected features
# selected_features = [feature_names[i] for i, is_selected in enumerate(top_k_features_mask) if is_selected]

# # Print selected features
# print("Selected Features: ", selected_features)

X_train.shape

print(f"Shape of X_train : {X_train.shape}")

"""## Models and Algorithm

### 1. Logistic Regression
"""

logistic_r = LogisticRegression(penalty='l2', C=0.0001)
logistic_r.fit(X_train, Y_train)

Y_logistic_r = logistic_r.predict(X_test)
Y_logistic_r

from sklearn.model_selection import cross_val_score

# Assuming you have X_train and Y_train
logistic_r = LogisticRegression(penalty='l2', C=0.1)
cv_scores_precision = cross_val_score(logistic_r, X_train, Y_train, cv=5, scoring='precision')
print(cv_scores_precision)

print(f"Accuracy : {accuracy_score(Y_test, Y_logistic_r)*100}%")
print(f"Confusion Matrix : \n {confusion_matrix(Y_test, Y_logistic_r)}")

"""### 2.Decision Tree Classifier"""

from sklearn.model_selection import GridSearchCV

# Create a decision tree classifier with initial regularization
decision_tree_classification = DecisionTreeClassifier(
    random_state=42,
    max_depth=5,  # Start with a shallower tree
    min_samples_split=100,  # Require more samples to split
    min_samples_leaf=30,  # Require more samples at leaf nodes
    max_features='sqrt',  # Consider fewer features at each split
    ccp_alpha=0.001  # Enable cost complexity pruning
)

# Define a grid of hyperparameters to explore
param_grid = {
    'max_depth': [5, 10, 15],
    'min_samples_split': [50, 100, 150],
    'min_samples_leaf': [20, 30, 40],
    'ccp_alpha': [0.001, 0.006 , 0.01],
}

# Perform grid search cross-validation to find optimal hyperparameters
grid_search = GridSearchCV(decision_tree_classification, param_grid, cv=5)
grid_search.fit(X_train, Y_train)

# Retrieve the best model
best_model = grid_search.best_estimator_

Y_DTc= best_model.predict(X_test)

print(f"Accuracy : {accuracy_score(Y_test, Y_DTc)*100}%")
print(f"Confusion Matrix : \n {confusion_matrix(Y_test, Y_DTc)}")

"""### 3. Random Forest Classifier"""

# param_grid = {
#     'n_estimators': [10, 20, 50, 100],
#     'max_depth': [None, 10, 20, 30],
#     'min_samples_split': [2, 5, 10],
#     'min_samples_leaf': [1, 2, 4]
# }
# random_forest_classification = RandomForestClassifier(n_estimators = 20, random_state=42)
# grid_search = GridSearchCV(random_forest_classification, param_grid, cv=5)
# grid_search.fit(X_train, Y_train)
# best_params = grid_search.best_params_
# best_random_forest = RandomForestClassifier(random_state=42, **best_params)
# best_random_forest.fit(X_train, Y_train)
# test_accuracy = best_random_forest.score(X_test, Y_test)
# print("Test Accuracy:", test_accuracy)

# Y_RF_class = random_forest_classification.predict(X_test)

# print(f"Accuracy : {accuracy_score(Y_test, Y_RF_class)*100}%")
# print(f"Confusion Matrix : \n {confusion_matrix(Y_test, Y_RF_class)}")

"""### 4. Neural Network approach"""

# model = Sequential()
# model.add(Input(X_train.shape[1]))
# model.add(Dense(64, activation='relu'))
# model.add(Dropout(0.5))
# model.add(Dense(128, activation='relu'))
# model.add(Dropout(0.5))
# model.add(Dense(256, activation='relu'))
# model.add(Dropout(0.5))
# model.add(Dense(16, activation='relu'))
# model.add(Dropout(0.5))
# model.add(Dense(1, activation='sigmoid'))

from tensorflow.keras import layers
model = tf.keras.Sequential([
    layers.Input(X_train.shape[1]),

    # Wider layers with more neurons:
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),

    # Stacked dense blocks for enhanced learning:
    layers.Dense(256, activation='relu'),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),

    # Batch normalization for regularization and stability:
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),

    # Output layer with sigmoid activation:
    layers.Dense(1, activation='sigmoid')
])

model.compile(loss = binary_crossentropy,
              optimizer = SGD(learning_rate = 0.001),
              metrics = [
                  BinaryAccuracy(name='accuracy'),
                  Precision(name='precision'),
                  Recall(name='recall')]
              )

model.summary()

history = model.fit(X_train, Y_train, epochs = 100,  validation_split = 0.25)

# i = np.arange(1, 11)

# fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)
# fig.set_figheight(12)
# fig.set_figwidth(18)

# ax1.plot(i, history.history['loss'])
# ax1.plot(i, history.history['val_loss'])
# ax1.set_xlabel('Epoch')
# ax1.set_ylabel('Loss')
# ax1.set_title('Loss vs Epoch')
# ax1.legend(['Training', 'Validation'])

# ax2.plot(i, history.history['accuracy'])
# ax2.plot(i, history.history['val_accuracy'])
# ax2.set_xlabel('Epoch')
# ax2.set_ylabel('Accuracy')
# ax2.set_title('Accuracy vs Epoch')
# ax2.legend(['Training', 'Validation'])

# ax3.plot(i, history.history['precision'])
# ax3.plot(i, history.history['val_precision'])
# ax3.set_xlabel('Epoch')
# ax3.set_ylabel('Precision')
# ax3.set_title('Precision vs Epoch')
# ax3.legend(['Training', 'Validation'])

# ax4.plot(i, history.history['recall'])
# ax4.plot(i, history.history['val_recall'])
# ax4.set_xlabel('Epoch')
# ax4.set_ylabel('Recall')
# ax4.set_title('Recall vs Epoch')
# ax4.legend(['Training', 'Validation'])

# plt.show()

Y_neural_net = model.predict(X_test)
Y_neural_net = [1 if i > 0.5 else 0 for i in list(Y_neural_net)]

print(f"Accuracy : {accuracy_score(Y_test, Y_neural_net)*100}%")
print(f"Confusion Matrix : \n {confusion_matrix(Y_test, Y_neural_net)}")

"""## Conclusion

All models work good but Neural Network gives the highest accuracy marginally i.e. 96.47%
"""

print(f"Accuracy by Logistic Regression : {accuracy_score(Y_test, Y_logistic_r)*100}%")
print(f"Accuracy by Decision Tree Classifier : {accuracy_score(Y_test, Y_DTc)*100}%")
#print(f"Accuracy by Random Forest Classifier : {accuracy_score(Y_test, Y_RF_class)*100}%")
print(f"Accuracy by Neural Network : {accuracy_score(Y_test, Y_neural_net)*100}%")

print(f"Confusion Matrix for Logistic Regression : \n {confusion_matrix(Y_test, Y_logistic_r)}")
print(f"Confusion Matrix for Decision Tree Classifier : \n {confusion_matrix(Y_test, Y_DTc)}")
#print(f"Confusion Matrix for Random Forest Classifier : \n {confusion_matrix(Y_test, Y_RF_class)}")
print(f"Confusion Matrix for Neural Network : \n {confusion_matrix(Y_test, Y_neural_net)}")

from sklearn.metrics import f1_score

f1 = f1_score(Y_test, Y_logistic_r)

print(f"F1 Score for Logistic regresson: {f1}")
#---------------------------------------------------------------------------
f1 = f1_score(Y_test, Y_DTc)

print(f"F1 Score for Decision tree     : {f1}")
#---------------------------------------------------------------------------
#f1 = f1_score(Y_test, Y_RF_class)

# print(f"F1 Score: {f1}")
#---------------------------------------------------------------------------
f1 = f1_score(Y_test, Y_neural_net)

print(f"F1 Score for Neural Network    : {f1}")

